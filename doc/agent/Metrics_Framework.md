# 产品评估指标框架 (Metrics Framework) - Karmada-Manager 增强

## 1. 指标框架概述

本指标框架旨在定义一套衡量 Karmada-Manager 增强功能成功与否的关键指标。通过对这些指标的持续追踪和分析，产品团队可以了解用户行为、评估产品价值、发现潜在问题，并指导未来的产品迭代和优化方向。本框架与 PRD 中定义的"产品成功指标"章节紧密相关。

**核心目标**: 量化产品目标的达成程度，确保产品迭代真正为用户带来价值，并提升 Karmada-Manager 的整体效能。

## 2. 北极星指标定义

-   **北极星指标**: **运维事件平均解决时长 (Mean Time To Resolution - MTTR) - 通过 Karmada-Manager 处理的与多集群管理和调度相关的运维任务**
    -   **定义**: 用户（特别是运维工程师）在使用 Karmada-Manager 执行典型的多集群管理任务（如查看集群/节点状态、诊断 Pod 问题、验证调度策略、调整配置）时，从任务开始到任务成功完成（问题解决或信息获取）所花费的平均时间。
    -   **选择依据**: 
        -   直接反映产品核心价值：提升运维效率。
        -   综合衡量多个增强功能（节点级可见性、调度追溯、资源查看/编辑、日志/事件查看）的整体效果。
        -   与用户核心痛点（多集群管理复杂、排障耗时）直接相关。
        -   是一个可量化、可追踪、可驱动行动的指标。
    -   **计算方式示例 (需根据实际埋点和数据收集能力调整)**:
        -   对于"Pod 调度问题排查"场景：记录用户从进入 Pod 列表/详情页开始，到最终确认 Pod 调度到特定节点的原因（可能通过查看调度策略、节点信息、事件等操作）的时间。
        -   对于"成员集群资源查看/调整"场景：记录用户从定位到特定成员集群的特定资源，到完成查看或修改操作的时间。
    -   **目标**: 持续降低此项指标。

## 3. 核心指标体系 (HEART Framework 变种 + 特定任务指标)

我们将结合 HEART (Happiness, Engagement, Adoption, Retention, Task Success) 框架的部分理念，并补充针对 Karmada-Manager 特定场景的任务成功率和效率指标。

### 3.1 用户满意度 (Happiness)

-   **指标1: 用户调研问卷 (NPS - Net Promoter Score)**
    -   **描述**: 定期（如每个大版本发布后）通过问卷询问用户"您有多大可能向同事或朋友推荐 Karmada-Manager 的这些新功能？"
    -   **收集方式**: 在线问卷。
    -   **目标**: NPS > 20 (初期)，持续提升。
-   **指标2: 功能满意度评分**
    -   **描述**: 在特定新功能使用路径结束后，邀请用户对该功能进行1-5星评分。
    -   **收集方式**: 产品内嵌简易评分。
    -   **目标**: 平均分 > 4.0。

### 3.2 用户参与度 (Engagement)

-   **指标3: 日活跃用户 (DAU) / 月活跃用户 (MAU)**
    -   **描述**: 衡量使用 Karmada-Manager 的用户规模和粘性。
    -   **收集方式**: 后端日志分析或前端埋点。
    -   **目标**: MAU 在 MVP 发布后3个月增长 X%，DAU/MAU 比率 > Y%。
-   **指标4: 核心功能模块使用频率/渗透率**
    -   **描述**: 
        -   "成员集群节点详情"查看次数/DAU。
        -   "Pod 调度追溯"功能使用次数/DAU。
        -   "成员集群资源查看 (YAML)"功能使用次数/DAU。
        -   "Pod 日志查看"功能使用次数/DAU。
    -   **收集方式**: 前端/后端埋点。
    -   **目标**: 核心功能渗透率达到 Z% 的活跃用户。
-   **指标5: 平均会话时长**
    -   **描述**: 用户单次使用 Karmada-Manager 的平均时长。 (需要结合任务成功率分析，时长过长也可能意味着效率低)。
    -   **收集方式**: 前端埋点。
    -   **目标**: 观察趋势，并结合其他指标解读。

### 3.3 功能采纳度 (Adoption)

-   **指标6: 新功能首次使用用户数/比例**
    -   **描述**: 每个新版本发布后，使用新增核心功能的用户数量及其在总活跃用户中的占比。
    -   **收集方式**: 前端/后端埋点。
    -   **目标**: 新功能在发布后1个月内被 A% 的MAU使用。
-   **指标7: 特定功能路径转化率**
    -   **描述**: 例如，从"查看 Deployment" -> "查看其关联的 PropagationPolicy" -> "查看 Pod 列表" -> "查看特定 Pod 调度追溯信息" 的用户路径转化率。
    -   **收集方式**: 前端埋点。
    -   **目标**: 关键用户路径的转化率 > B%。

### 3.4 任务成功与效率 (Task Success & Efficiency) - (此部分强化北极星指标)

-   **指标8: (北极星指标细化) 特定运维任务平均完成时长**
    -   **描述**: 
        -   场景A (查看 Pod 最终部署节点及原因) 平均时长。
        -   场景B (查看成员集群某节点资源使用详情) 平均时长。
        -   场景C (查看 Workload 在各集群的副本分布) 平均时长。
    -   **收集方式**: 精细化前端埋点，记录关键操作节点的时间戳。
    -   **目标**: 各核心场景的平均时长持续下降。
-   **指标9: 特定任务一次性成功率**
    -   **描述**: 用户在执行特定任务时，没有发生错误或异常退出，一次性完成的比例。
        -   例如：成功查看到 Pod 日志的会话比例。
        -   例如：成功应用 ConfigMap 修改的会话比例 (如果实现了编辑)。
    -   **收集方式**: 前端/后端埋点，记录任务完成状态和错误事件。
    -   **目标**: 核心任务一次性成功率 > 95%。
-   **指标10: 错误率**
    -   **描述**: 
        -   API 调用错误率 (按接口统计)。
        -   前端 JavaScript 错误率。
        -   用户操作导致的可识别的错误提示出现频率。
    -   **收集方式**: 后端监控，前端错误上报，埋点。
    -   **目标**: API 错误率 < 0.1%，前端严重错误得到及时修复。

## 4. 功能级评估指标 (示例)

| 功能模块                 | 关键指标                                                                 | PRD 功能点         |
| ------------------------ | ------------------------------------------------------------------------ | ------------------ |
| **成员集群节点管理**     | - 节点列表加载时间 < X 秒<br>- 节点详情查看次数/DAU<br>- 从节点查看其上 Pods 的转化率 | 5.2.1              |
| **成员集群资源查看/编辑**| - 资源 YAML 查看次数/DAU<br>- (若实现) ConfigMap 编辑成功率<br>- Pod 日志查看平均时长 | 5.2.1              |
| **调度策略可视化**       | - PropagationPolicy 效果可视化查看次数/DAU<br>- 用户对可视化清晰度的评分     | 5.2.2              |
| **Pod 调度路径追溯**     | - Pod 调度追溯功能使用频率<br>- 用户找到"调度原因"的平均步骤数/时长          | 5.2.2              |

## 5. 指标监测计划

-   **数据收集工具**: 
    -   前端埋点: 使用成熟的前端统计库 (如 Google Analytics, Mixpanel, 或自建方案)。
    -   后端日志: 结构化日志，方便进行聚合分析。
    -   APM 系统: (如 SkyWalking, Prometheus) 监控后端 API 性能和错误。
-   **数据看板与报告**: 
    -   建立核心指标的数据看板 (如使用 Grafana, Superset 或 BI 工具)。
    -   定期（如每周/每两周）生成产品指标报告，包含数据趋势、异动分析和洞察。
-   **回顾与迭代**: 
    -   产品团队定期（如每月）回顾指标数据，评估产品目标的达成情况。
    -   根据数据洞察和用户反馈，调整产品策略和后续迭代计划。
-   **A/B 测试 (如适用)**: 
    -   对于某些重要的 UI 变更或功能优化，可以考虑使用 A/B 测试来对比不同方案的效果，基于数据决策。

**责任分配 (初步建议)**:

-   **产品经理**: 定义指标，跟踪数据，分析报告，驱动决策。
-   **开发团队**: 负责埋点实现，确保数据采集的准确性和完整性，监控系统性能指标。
-   **QA 团队**: 验证埋点的正确性。
-   **(可选) 数据分析师**: 协助进行深度数据分析和建模。 