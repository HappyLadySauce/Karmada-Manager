#!/bin/bash

# Karmada Dashboard è°ƒåº¦æ¥å£æµ‹è¯•è„šæœ¬
# ä¸“é—¨æµ‹è¯• cmd/api/app/routes/scheduling/handler.go ä¸­å®šä¹‰çš„è°ƒåº¦ç›¸å…³ API æ¥å£

# ä¸è¦åœ¨é”™è¯¯æ—¶ç«‹å³é€€å‡ºï¼Œè®©è„šæœ¬ç»§ç»­è¿è¡Œå®Œæ‰€æœ‰æµ‹è¯•
# set -e  # æ³¨é‡Šæ‰è¿™è¡Œ

# é»˜è®¤é…ç½®
API_BASE_URL="${API_BASE_URL:-http://localhost:8000}"
API_VERSION="v1"
TOKEN="${TOKEN:-}"
VERBOSE="${VERBOSE:-false}"

# æ–°å¢é…ç½®å‚æ•°
TIMEOUT="${TIMEOUT:-30}"                    # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
MAX_RETRIES="${MAX_RETRIES:-3}"            # å¤±è´¥è¯·æ±‚æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_DELAY="${RETRY_DELAY:-2}"            # é‡è¯•é—´éš”(ç§’)
CONCURRENCY="${CONCURRENCY:-5}"            # å‹åŠ›æµ‹è¯•å¹¶å‘æ•°
OUTPUT_FORMAT="${OUTPUT_FORMAT:-console}"   # è¾“å‡ºæ ¼å¼: console/json/junit
LOG_LEVEL="${LOG_LEVEL:-INFO}"             # æ—¥å¿—çº§åˆ«: DEBUG/INFO/WARN/ERROR
TEST_SUITE="${TEST_SUITE:-all}"            # æµ‹è¯•å¥—ä»¶: all/health/workload/overview/namespace/stress
SKIP_HEALTH_CHECK="${SKIP_HEALTH_CHECK:-false}"  # è·³è¿‡å¥åº·æ£€æŸ¥
SAVE_RESPONSES="${SAVE_RESPONSES:-false}"   # ä¿å­˜å“åº”åˆ°æ–‡ä»¶
OUTPUT_FILE="${OUTPUT_FILE:-}"             # æµ‹è¯•ç»“æœè¾“å‡ºæ–‡ä»¶
PROXY="${PROXY:-}"                         # HTTPä»£ç†è®¾ç½®
CUSTOM_HEADERS="${CUSTOM_HEADERS:-}"       # è‡ªå®šä¹‰è¯·æ±‚å¤´ (æ ¼å¼: "Header1:Value1,Header2:Value2")
TEST_DATA_FILE="${TEST_DATA_FILE:-}"       # æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„
FAIL_FAST="${FAIL_FAST:-false}"           # é‡åˆ°å¤±è´¥ç«‹å³åœæ­¢

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# æµ‹è¯•ç»Ÿè®¡
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0
SKIPPED_TESTS=0

# æµ‹è¯•ç»“æœæ•°ç»„ (ç”¨äºJSONè¾“å‡º)
declare -a TEST_RESULTS=()

# å“åº”ä¿å­˜ç›®å½•
RESPONSE_DIR="/tmp/scheduling_api_responses"

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[PASS]${NC} $1"
    ((PASSED_TESTS++))
}

log_error() {
    echo -e "${RED}[FAIL]${NC} $1"
    ((FAILED_TESTS++))
}

log_warning() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_debug() {
    if [[ "$VERBOSE" == "true" ]] || [[ "$LOG_LEVEL" == "DEBUG" ]]; then
        echo -e "${CYAN}[DEBUG]${NC} $1"
    fi
}

log_header() {
    echo -e "${PURPLE}[HEADER]${NC} $1"
}

log_skip() {
    echo -e "${YELLOW}[SKIP]${NC} $1"
    ((SKIPPED_TESTS++))
}

# æ£€æŸ¥æ—¥å¿—çº§åˆ«
should_log() {
    local level="$1"
    case "$LOG_LEVEL" in
        "DEBUG") return 0 ;;
        "INFO") [[ "$level" != "DEBUG" ]] && return 0 || return 1 ;;
        "WARN") [[ "$level" =~ ^(WARN|ERROR)$ ]] && return 0 || return 1 ;;
        "ERROR") [[ "$level" == "ERROR" ]] && return 0 || return 1 ;;
        *) return 0 ;;
    esac
}

# å¢åŠ æµ‹è¯•è®¡æ•°
count_test() {
    ((TOTAL_TESTS++))
}

# é‡è¯•æœºåˆ¶å‡½æ•°
retry_request() {
    local command="$1"
    local max_retries="$2"
    local delay="$3"
    local attempt=1
    
    while [[ $attempt -le $max_retries ]]; do
        if eval "$command"; then
            return 0
        fi
        
        if [[ $attempt -lt $max_retries ]]; then
            log_warning "â³ è¯·æ±‚å¤±è´¥ï¼Œ${delay}ç§’åè¿›è¡Œç¬¬${attempt}æ¬¡é‡è¯•..."
            sleep "$delay"
        fi
        
        ((attempt++))
    done
    
    return 1
}

# ä¿å­˜å“åº”åˆ°æ–‡ä»¶
save_response() {
    local test_name="$1"
    local response_content="$2"
    local http_code="$3"
    
    if [[ "$SAVE_RESPONSES" == "true" ]]; then
        mkdir -p "$RESPONSE_DIR"
        local filename="${RESPONSE_DIR}/$(echo "$test_name" | tr ' ' '_' | tr '/' '_').json"
        local response_data="{\"test_name\":\"$test_name\",\"http_code\":\"$http_code\",\"timestamp\":\"$(date -Iseconds)\",\"response\":$response_content}"
        echo "$response_data" > "$filename"
        log_debug "å“åº”å·²ä¿å­˜åˆ°: $filename"
    fi
}

# æ·»åŠ æµ‹è¯•ç»“æœåˆ°æ•°ç»„
add_test_result() {
    local test_name="$1"
    local status="$2"
    local http_code="$3"
    local message="$4"
    local duration="$5"
    
    local result="{\"name\":\"$test_name\",\"status\":\"$status\",\"http_code\":\"$http_code\",\"message\":\"$message\",\"duration\":\"$duration\",\"timestamp\":\"$(date -Iseconds)\"}"
    TEST_RESULTS+=("$result")
}

# å‘é€ HTTP è¯·æ±‚çš„é€šç”¨å‡½æ•° (å¢å¼ºç‰ˆ)
make_request() {
    local method="$1"
    local endpoint="$2"
    local data="$3"
    local expected_codes="$4"
    local test_name="$5"
    
    count_test
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¿™ä¸ªæµ‹è¯•
    if should_skip_test "$test_name"; then
        log_skip "è·³è¿‡æµ‹è¯•: $test_name"
        add_test_result "$test_name" "SKIPPED" "N/A" "Test skipped based on configuration" "0"
        return 0
    fi
    
    local start_time=$(date +%s.%N)
    local url="${API_BASE_URL}/api/${API_VERSION}${endpoint}"
    local response_file="/tmp/scheduling_api_response_$(date +%s%N).json"
    local curl_opts=("-s" "-w" "%{http_code}" "-o" "$response_file" "--max-time" "$TIMEOUT")
    
    # æ·»åŠ ä»£ç†è®¾ç½®
    if [[ -n "$PROXY" ]]; then
        curl_opts+=("--proxy" "$PROXY")
        log_debug "ä½¿ç”¨ä»£ç†: $PROXY"
    fi
    
    # æ·»åŠ è®¤è¯å¤´
    if [[ -n "$TOKEN" ]]; then
        curl_opts+=("-H" "Authorization: Bearer $TOKEN")
        log_debug "ä½¿ç”¨è®¤è¯ Token: ${TOKEN:0:20}..."
    fi
    
    # æ·»åŠ  Content-Type
    curl_opts+=("-H" "Content-Type: application/json")
    
    # æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´
    if [[ -n "$CUSTOM_HEADERS" ]]; then
        IFS=',' read -ra HEADERS <<< "$CUSTOM_HEADERS"
        for header in "${HEADERS[@]}"; do
            curl_opts+=("-H" "$header")
            log_debug "æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´: $header"
        done
    fi
    
    # æ·»åŠ è¯·æ±‚æ–¹æ³•å’Œæ•°æ®
    curl_opts+=("-X" "$method")
    if [[ -n "$data" ]]; then
        curl_opts+=("-d" "$data")
        log_debug "è¯·æ±‚æ•°æ®: $data"
    fi
    
    # æ·»åŠ  URL
    curl_opts+=("$url")
    
    should_log "INFO" && log_info "ğŸš€ æµ‹è¯•: $test_name"
    should_log "INFO" && log_info "ğŸ“¡ è¯·æ±‚: $method $url"
    
    if [[ "$VERBOSE" == "true" ]] || [[ "$LOG_LEVEL" == "DEBUG" ]]; then
        log_debug "å®Œæ•´ curl å‘½ä»¤: curl ${curl_opts[*]}"
    fi
    
    # æ‰§è¡Œè¯·æ±‚ (å¸¦é‡è¯•æœºåˆ¶)
    local http_code=""
    local curl_command="http_code=\$(curl \"\${curl_opts[@]}\" 2>/tmp/scheduling_curl_error.log || echo \"000\")"
    
    if ! retry_request "$curl_command" "$MAX_RETRIES" "$RETRY_DELAY"; then
        http_code="000"
    fi
    
    local end_time=$(date +%s.%N)
    local duration=$(echo "$end_time - $start_time" | bc -l 2>/dev/null || echo "0")
    
    # è¯»å–å“åº”å†…å®¹
    local response_content=""
    if [[ -f "$response_file" ]]; then
        response_content=$(cat "$response_file" 2>/dev/null || echo "{}")
    else
        response_content="{}"
    fi
    
    # è¯»å– curl é”™è¯¯ä¿¡æ¯
    local curl_error=""
    if [[ -f "/tmp/scheduling_curl_error.log" ]]; then
        curl_error=$(cat /tmp/scheduling_curl_error.log 2>/dev/null || echo "")
    fi
    
    # æ˜¾ç¤ºå“åº”ä¿¡æ¯
    should_log "INFO" && log_info "ğŸ“¥ å“åº”çŠ¶æ€ç : $http_code"
    should_log "INFO" && log_info "â±ï¸  å“åº”æ—¶é—´: ${duration}s"
    
    if [[ -n "$curl_error" ]]; then
        should_log "ERROR" && log_error "âŒ Curl é”™è¯¯: $curl_error"
    fi
    
    # æ˜¾ç¤ºå“åº”å†…å®¹
    if [[ -n "$response_content" ]] && [[ "$response_content" != "{}" ]]; then
        should_log "DEBUG" && log_debug "ğŸ“„ å“åº”å†…å®¹ (å®Œæ•´æ•°æ®):"
        if should_log "DEBUG" && command -v jq &> /dev/null; then
            echo "$response_content" | jq . 2>/dev/null || echo "$response_content"
        elif should_log "DEBUG"; then
            echo "$response_content"
        fi
    elif [[ "$http_code" != "000" ]] && should_log "DEBUG"; then
        log_debug "ğŸ“„ å“åº”å†…å®¹: (ç©º)"
    fi
    
    # ä¿å­˜å“åº”
    save_response "$test_name" "$response_content" "$http_code"
    
    # æ£€æŸ¥å“åº”ç å¹¶è®°å½•ç»“æœ
    local test_status=""
    local test_message=""
    
    if [[ "$expected_codes" == *"$http_code"* ]]; then
        should_log "INFO" && log_success "$test_name âœ…"
        test_status="PASSED"
        test_message="HTTP code $http_code as expected"
    else
        should_log "ERROR" && log_error "$test_name âŒ (çŠ¶æ€ç : $http_code, æœŸæœ›: $expected_codes)"
        test_status="FAILED"
        test_message="HTTP code $http_code, expected: $expected_codes"
        
        # å¦‚æœè®¾ç½®äº†å¿«é€Ÿå¤±è´¥ï¼Œåˆ™é€€å‡º
        if [[ "$FAIL_FAST" == "true" ]]; then
            log_error "ğŸ’¥ å¿«é€Ÿå¤±è´¥æ¨¡å¼å·²å¯ç”¨ï¼Œæµ‹è¯•åœæ­¢"
            cleanup_and_exit 1
        fi
    fi
    
    # æ·»åŠ æµ‹è¯•ç»“æœ
    add_test_result "$test_name" "$test_status" "$http_code" "$test_message" "$duration"
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f "$response_file"
    
    should_log "DEBUG" && echo "----------------------------------------"
}

# åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æµ‹è¯•
should_skip_test() {
    local test_name="$1"
    
    # æ ¹æ®æµ‹è¯•å¥—ä»¶è®¾ç½®åˆ¤æ–­æ˜¯å¦è·³è¿‡
    case "$TEST_SUITE" in
        "health")
            [[ "$test_name" != *"å¥åº·æ£€æŸ¥"* ]] && return 0
            ;;
        "workload")
            [[ "$test_name" != *"å·¥ä½œè´Ÿè½½"* ]] && [[ "$test_name" != *"Deployment"* ]] && [[ "$test_name" != *"StatefulSet"* ]] && [[ "$test_name" != *"DaemonSet"* ]] && return 0
            ;;
        "overview")
            [[ "$test_name" != *"æ¦‚è§ˆ"* ]] && [[ "$test_name" != *"overview"* ]] && return 0
            ;;
        "namespace")
            [[ "$test_name" != *"å‘½åç©ºé—´"* ]] && [[ "$test_name" != *"namespace"* ]] && return 0
            ;;
        "stress")
            [[ "$test_name" != *"å¹¶å‘"* ]] && [[ "$test_name" != *"å‹åŠ›"* ]] && [[ "$test_name" != *"è¿ç»­"* ]] && return 0
            ;;
        "all")
            # è¿è¡Œæ‰€æœ‰æµ‹è¯•
            return 1
            ;;
    esac
    
    return 1
}

# è¾“å‡ºä¸åŒæ ¼å¼çš„æµ‹è¯•ç»“æœ
output_test_results() {
    case "$OUTPUT_FORMAT" in
        "json")
            output_json_results
            ;;
        "junit")
            output_junit_results
            ;;
        "console")
            # é»˜è®¤æ§åˆ¶å°è¾“å‡ºï¼Œå·²ç»åœ¨ä¸»æµç¨‹ä¸­å¤„ç†
            ;;
    esac
}

# è¾“å‡ºJSONæ ¼å¼ç»“æœ
output_json_results() {
    local json_output=""
    json_output=$(cat << EOF
{
  "summary": {
    "total": $TOTAL_TESTS,
    "passed": $PASSED_TESTS,
    "failed": $FAILED_TESTS,
    "skipped": $SKIPPED_TESTS,
    "success_rate": $(( TOTAL_TESTS > 0 ? PASSED_TESTS * 100 / TOTAL_TESTS : 0 )),
    "timestamp": "$(date -Iseconds)",
    "duration": "${duration}s"
  },
  "tests": [
$(IFS=,; echo "${TEST_RESULTS[*]}")
  ]
}
EOF
)
    
    if [[ -n "$OUTPUT_FILE" ]]; then
        echo "$json_output" > "$OUTPUT_FILE"
        log_info "ğŸ“„ JSON æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: $OUTPUT_FILE"
    else
        echo "$json_output"
    fi
}

# è¾“å‡ºJUnitæ ¼å¼ç»“æœ
output_junit_results() {
    local junit_file="${OUTPUT_FILE:-scheduling_test_results.xml}"
    
    cat > "$junit_file" << EOF
<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="Karmada Scheduling API Tests" 
           tests="$TOTAL_TESTS" 
           failures="$FAILED_TESTS" 
           skipped="$SKIPPED_TESTS" 
           time="$duration">
EOF
    
    for result in "${TEST_RESULTS[@]}"; do
        local name=$(echo "$result" | jq -r '.name' 2>/dev/null || echo "unknown")
        local status=$(echo "$result" | jq -r '.status' 2>/dev/null || echo "unknown")
        local message=$(echo "$result" | jq -r '.message' 2>/dev/null || echo "")
        local test_duration=$(echo "$result" | jq -r '.duration' 2>/dev/null || echo "0")
        
        echo "  <testcase name=\"$name\" time=\"$test_duration\">" >> "$junit_file"
        
        case "$status" in
            "FAILED")
                echo "    <failure message=\"$message\"/>" >> "$junit_file"
                ;;
            "SKIPPED")
                echo "    <skipped message=\"$message\"/>" >> "$junit_file"
                ;;
        esac
        
        echo "  </testcase>" >> "$junit_file"
    done
    
    echo "</testsuite>" >> "$junit_file"
    log_info "ğŸ“„ JUnit æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: $junit_file"
}

# æ¸…ç†å’Œé€€å‡ºå‡½æ•°
cleanup_and_exit() {
    local exit_code="${1:-0}"
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f /tmp/scheduling_api_response*.json /tmp/scheduling_curl_error.log
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    output_test_results
    
    exit "$exit_code"
}

# å¥åº·æ£€æŸ¥æµ‹è¯•
test_health_check() {
    if [[ "$SKIP_HEALTH_CHECK" == "true" ]]; then
        log_skip "â­ï¸  è·³è¿‡å¥åº·æ£€æŸ¥æµ‹è¯•"
        return 0
    fi
    
    log_header "ğŸ” å¼€å§‹å¥åº·æ£€æŸ¥æµ‹è¯•..."
    
    count_test
    local url="${API_BASE_URL}/health"
    
    log_info "ğŸš€ æµ‹è¯•: å¥åº·æ£€æŸ¥"
    log_info "ğŸ“¡ è¯·æ±‚: GET $url"
    
    local http_code
    local response_content
    
    # æ‰§è¡Œå¥åº·æ£€æŸ¥è¯·æ±‚
    response_content=$(curl -s -w "\n%{http_code}" "$url" 2>/tmp/scheduling_curl_error.log || echo -e "\n000")
    http_code=$(echo "$response_content" | tail -n1)
    response_content=$(echo "$response_content" | head -n -1)
    
    # è¯»å– curl é”™è¯¯ä¿¡æ¯
    local curl_error=""
    if [[ -f "/tmp/scheduling_curl_error.log" ]]; then
        curl_error=$(cat /tmp/scheduling_curl_error.log 2>/dev/null || echo "")
    fi
    
    log_info "ğŸ“¥ å“åº”çŠ¶æ€ç : $http_code"
    
    if [[ -n "$curl_error" ]]; then
        log_error "âŒ Curl é”™è¯¯: $curl_error"
    fi
    
    if [[ -n "$response_content" ]]; then
        log_info "ğŸ“„ å“åº”å†…å®¹ (å®Œæ•´æ•°æ®):"
        if command -v jq &> /dev/null; then
            echo "$response_content" | jq . 2>/dev/null || echo "$response_content"
        else
            echo "$response_content"
        fi
    fi
    
    if [[ "$http_code" == "200" ]]; then
        log_success "å¥åº·æ£€æŸ¥ âœ…"
    else
        log_error "å¥åº·æ£€æŸ¥ âŒ (çŠ¶æ€ç : $http_code)"
        if [[ "$http_code" == "000" ]]; then
            log_warning "ğŸ’¡ æç¤º: å¯èƒ½æ˜¯æœåŠ¡æœªå¯åŠ¨æˆ–ç½‘ç»œè¿æ¥é—®é¢˜"
        fi
    fi
    
    echo "----------------------------------------"
}

# å·¥ä½œè´Ÿè½½è°ƒåº¦æ¥å£æµ‹è¯•
test_workload_scheduling_apis() {
    log_header "ğŸ“‹ å¼€å§‹å·¥ä½œè´Ÿè½½è°ƒåº¦æ¥å£æµ‹è¯•..."
    
    # æµ‹è¯•ç”¨çš„å·¥ä½œè´Ÿè½½ä¿¡æ¯
    local namespaces=("default" "kube-system" "test-namespace")
    local workload_names=("nginx-deployment" "test-deployment" "example-app")
    local workload_kinds=("Deployment" "StatefulSet" "DaemonSet")
    
    for namespace in "${namespaces[@]}"; do
        for workload_name in "${workload_names[@]}"; do
            for kind in "${workload_kinds[@]}"; do
                log_info "ğŸ” æµ‹è¯•å·¥ä½œè´Ÿè½½: $namespace/$workload_name (kind: $kind)"
                
                # æµ‹è¯•åŸºç¡€è°ƒåº¦ä¿¡æ¯
                make_request "GET" "/workloads/$namespace/$workload_name/scheduling?kind=$kind" "" "200 401 403 404 500" "è·å–${kind}åŸºç¡€è°ƒåº¦ä¿¡æ¯"
                
                # æµ‹è¯•ç²¾ç¡®è°ƒåº¦ä¿¡æ¯
                make_request "GET" "/workloads/$namespace/$workload_name/precise-scheduling?kind=$kind" "" "200 401 403 404 500" "è·å–${kind}ç²¾ç¡®è°ƒåº¦ä¿¡æ¯"
            done
        done
    done
    
    # æµ‹è¯•é»˜è®¤ kind (Deployment)
    log_info "ğŸ” æµ‹è¯•é»˜è®¤ kind (Deployment)"
    make_request "GET" "/workloads/default/nginx-deployment/scheduling" "" "200 401 403 404 500" "è·å–é»˜è®¤Deploymentè°ƒåº¦ä¿¡æ¯"
    make_request "GET" "/workloads/default/nginx-deployment/precise-scheduling" "" "200 401 403 404 500" "è·å–é»˜è®¤Deploymentç²¾ç¡®è°ƒåº¦ä¿¡æ¯"
    
    # æµ‹è¯•ç‰¹æ®Šæƒ…å†µ
    log_info "ğŸ” æµ‹è¯•ç‰¹æ®Šæƒ…å†µå’Œè¾¹ç•Œæ¡ä»¶"
    
    # ä¸å­˜åœ¨çš„å‘½åç©ºé—´
    make_request "GET" "/workloads/non-existent-namespace/test-deployment/scheduling" "" "404 401 403 500" "ä¸å­˜åœ¨çš„å‘½åç©ºé—´"
    
    # ä¸å­˜åœ¨çš„å·¥ä½œè´Ÿè½½
    make_request "GET" "/workloads/default/non-existent-deployment/scheduling" "" "404 401 403 500" "ä¸å­˜åœ¨çš„å·¥ä½œè´Ÿè½½"
    
    # æ— æ•ˆçš„ kind
    make_request "GET" "/workloads/default/test-deployment/scheduling?kind=InvalidKind" "" "400 404 401 403 500" "æ— æ•ˆçš„å·¥ä½œè´Ÿè½½ç±»å‹"
    
    # ç©ºçš„å·¥ä½œè´Ÿè½½åç§°ï¼ˆè¿™ä¼šå¯¼è‡´è·¯ç”±ä¸åŒ¹é…ï¼‰
    make_request "GET" "/workloads/default//scheduling" "" "404 401 403" "ç©ºçš„å·¥ä½œè´Ÿè½½åç§°"
    
    # ç‰¹æ®Šå­—ç¬¦åœ¨åç§°ä¸­
    make_request "GET" "/workloads/default/test-deployment-with-special-chars/scheduling" "" "200 404 401 403 500" "åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å·¥ä½œè´Ÿè½½åç§°"
}

# è°ƒåº¦æ¦‚è§ˆæ¥å£æµ‹è¯•
test_scheduling_overview_apis() {
    log_header "ğŸ“Š å¼€å§‹è°ƒåº¦æ¦‚è§ˆæ¥å£æµ‹è¯•..."
    
    # æµ‹è¯•åŸºç¡€æ¦‚è§ˆæ¥å£
    make_request "GET" "/scheduling/overview" "" "200 401 403 500" "è·å–è°ƒåº¦æ¦‚è§ˆä¿¡æ¯"
    
    # æµ‹è¯•å¸¦å‘½åç©ºé—´è¿‡æ»¤çš„æ¦‚è§ˆæ¥å£
    local namespaces=("default" "kube-system" "test-namespace" "")
    
    for namespace in "${namespaces[@]}"; do
        if [[ -n "$namespace" ]]; then
            log_info "ğŸ” æµ‹è¯•å‘½åç©ºé—´è¿‡æ»¤: $namespace"
            make_request "GET" "/scheduling/overview?namespace=$namespace" "" "200 401 403 404 500" "è·å–${namespace}å‘½åç©ºé—´è°ƒåº¦æ¦‚è§ˆ"
        else
            log_info "ğŸ” æµ‹è¯•ç©ºå‘½åç©ºé—´è¿‡æ»¤"
            make_request "GET" "/scheduling/overview?namespace=" "" "200 401 403 500" "è·å–ç©ºå‘½åç©ºé—´è¿‡æ»¤è°ƒåº¦æ¦‚è§ˆ"
        fi
    done
    
    # æµ‹è¯•ä¸å­˜åœ¨çš„å‘½åç©ºé—´
    make_request "GET" "/scheduling/overview?namespace=non-existent-namespace" "" "200 404 401 403 500" "ä¸å­˜åœ¨çš„å‘½åç©ºé—´æ¦‚è§ˆ"
}

# å‘½åç©ºé—´å·¥ä½œè´Ÿè½½è°ƒåº¦æ¥å£æµ‹è¯•
test_namespace_workloads_scheduling_apis() {
    log_header "ğŸ“ å¼€å§‹å‘½åç©ºé—´å·¥ä½œè´Ÿè½½è°ƒåº¦æ¥å£æµ‹è¯•..."
    
    local namespaces=("default" "kube-system" "test-namespace")
    
    for namespace in "${namespaces[@]}"; do
        log_info "ğŸ” æµ‹è¯•å‘½åç©ºé—´: $namespace"
        
        # åŸºç¡€æµ‹è¯•
        make_request "GET" "/scheduling/namespace/$namespace/workloads" "" "200 401 403 404 500" "è·å–${namespace}å‘½åç©ºé—´å·¥ä½œè´Ÿè½½è°ƒåº¦ä¿¡æ¯"
        
        # æµ‹è¯•åˆ†é¡µå‚æ•°
        make_request "GET" "/scheduling/namespace/$namespace/workloads?page=1&pageSize=10" "" "200 401 403 404 500" "åˆ†é¡µè·å–${namespace}å‘½åç©ºé—´å·¥ä½œè´Ÿè½½(ç¬¬1é¡µ,10æ¡)"
        make_request "GET" "/scheduling/namespace/$namespace/workloads?page=2&pageSize=20" "" "200 401 403 404 500" "åˆ†é¡µè·å–${namespace}å‘½åç©ºé—´å·¥ä½œè´Ÿè½½(ç¬¬2é¡µ,20æ¡)"
        
        # æµ‹è¯• kind è¿‡æ»¤
        local kinds=("Deployment" "StatefulSet" "DaemonSet" "Job" "CronJob")
        for kind in "${kinds[@]}"; do
            make_request "GET" "/scheduling/namespace/$namespace/workloads?kind=$kind" "" "200 401 403 404 500" "è·å–${namespace}å‘½åç©ºé—´${kind}è°ƒåº¦ä¿¡æ¯"
        done
        
        # æµ‹è¯•ç»„åˆå‚æ•°
        make_request "GET" "/scheduling/namespace/$namespace/workloads?page=1&pageSize=5&kind=Deployment" "" "200 401 403 404 500" "ç»„åˆå‚æ•°è·å–${namespace}å‘½åç©ºé—´Deploymentè°ƒåº¦ä¿¡æ¯"
    done
    
    # æµ‹è¯•è¾¹ç•Œæ¡ä»¶
    log_info "ğŸ” æµ‹è¯•è¾¹ç•Œæ¡ä»¶"
    
    # ä¸å­˜åœ¨çš„å‘½åç©ºé—´
    make_request "GET" "/scheduling/namespace/non-existent-namespace/workloads" "" "404 401 403 500" "ä¸å­˜åœ¨çš„å‘½åç©ºé—´å·¥ä½œè´Ÿè½½è°ƒåº¦"
    
    # æ— æ•ˆçš„åˆ†é¡µå‚æ•°
    make_request "GET" "/scheduling/namespace/default/workloads?page=0&pageSize=0" "" "200 400 401 403 500" "æ— æ•ˆçš„åˆ†é¡µå‚æ•°(page=0,pageSize=0)"
    make_request "GET" "/scheduling/namespace/default/workloads?page=-1&pageSize=-5" "" "200 400 401 403 500" "è´Ÿæ•°åˆ†é¡µå‚æ•°"
    make_request "GET" "/scheduling/namespace/default/workloads?page=abc&pageSize=xyz" "" "200 400 401 403 500" "éæ•°å­—åˆ†é¡µå‚æ•°"
    
    # æ— æ•ˆçš„ kind
    make_request "GET" "/scheduling/namespace/default/workloads?kind=InvalidKind" "" "200 400 401 403 500" "æ— æ•ˆçš„å·¥ä½œè´Ÿè½½ç±»å‹è¿‡æ»¤"
    
    # å¤§åˆ†é¡µå‚æ•°
    make_request "GET" "/scheduling/namespace/default/workloads?page=1000&pageSize=1000" "" "200 401 403 500" "å¤§åˆ†é¡µå‚æ•°æµ‹è¯•"
}

# åŠ è½½æµ‹è¯•æ•°æ®æ–‡ä»¶
load_test_data() {
    if [[ -n "$TEST_DATA_FILE" ]] && [[ -f "$TEST_DATA_FILE" ]]; then
        log_info "ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æµ‹è¯•æ•°æ®: $TEST_DATA_FILE"
        source "$TEST_DATA_FILE"
        log_success "âœ… æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ"
    else
        log_debug "ä½¿ç”¨é»˜è®¤æµ‹è¯•æ•°æ®"
    fi
}

# å‹åŠ›æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
test_scheduling_stress_test() {
    if [[ "$STRESS_TEST" != "true" ]]; then
        log_info "ğŸ’¡ è·³è¿‡å‹åŠ›æµ‹è¯• (è®¾ç½® STRESS_TEST=true å¯ç”¨)"
        return 0
    fi
    
    log_header "âš¡ å¼€å§‹è°ƒåº¦æ¥å£å‹åŠ›æµ‹è¯•..."
    
    log_info "ğŸ”¥ å¹¶å‘è¯·æ±‚æµ‹è¯• (å¹¶å‘æ•°: $CONCURRENCY)"
    
    # å¹¶å‘è¯·æ±‚åŸºç¡€è°ƒåº¦ä¿¡æ¯
    local pids=()
    for ((i=1; i<=CONCURRENCY; i++)); do
        {
            make_request "GET" "/workloads/default/test-deployment/scheduling" "" "200 401 403 404 500" "å¹¶å‘æµ‹è¯•-åŸºç¡€è°ƒåº¦ä¿¡æ¯-$i"
        } &
        pids+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰å¹¶å‘è¯·æ±‚å®Œæˆ
    for pid in "${pids[@]}"; do
        wait "$pid"
    done
    
    log_info "ğŸ”¥ å¿«é€Ÿè¿ç»­è¯·æ±‚æµ‹è¯•"
    
    # å¿«é€Ÿè¿ç»­è¯·æ±‚
    for i in {1..20}; do
        make_request "GET" "/scheduling/overview" "" "200 401 403 500" "è¿ç»­è¯·æ±‚-è°ƒåº¦æ¦‚è§ˆ-$i"
    done
    
    log_info "ğŸ”¥ å¤§æ•°æ®é‡è¯·æ±‚æµ‹è¯•"
    
    # æµ‹è¯•å¤§åˆ†é¡µè¯·æ±‚
    make_request "GET" "/scheduling/namespace/default/workloads?pageSize=1000" "" "200 401 403 500" "å¤§åˆ†é¡µè¯·æ±‚æµ‹è¯•"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
Karmada Dashboard è°ƒåº¦æ¥å£æµ‹è¯•è„šæœ¬

ä¸“é—¨æµ‹è¯• cmd/api/app/routes/scheduling/handler.go ä¸­å®šä¹‰çš„è°ƒåº¦ç›¸å…³ API æ¥å£

ç”¨æ³•: $0 [é€‰é¡¹]

åŸºç¡€é€‰é¡¹:
    --url URL                API åŸºç¡€ URL (é»˜è®¤: http://localhost:8000)
    --token TOKEN            è®¤è¯ token
    --verbose               è¯¦ç»†è¾“å‡ºæ¨¡å¼
    --help                  æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

æµ‹è¯•æ§åˆ¶é€‰é¡¹:
    --suite SUITE           æµ‹è¯•å¥—ä»¶ (all/health/workload/overview/namespace/stress)
    --skip-health           è·³è¿‡å¥åº·æ£€æŸ¥
    --stress                å¯ç”¨å‹åŠ›æµ‹è¯•
    --fail-fast             é‡åˆ°å¤±è´¥ç«‹å³åœæ­¢
    --concurrency NUM       å‹åŠ›æµ‹è¯•å¹¶å‘æ•° (é»˜è®¤: 5)

ç½‘ç»œé€‰é¡¹:
    --timeout SECONDS       è¯·æ±‚è¶…æ—¶æ—¶é—´ (é»˜è®¤: 30ç§’)
    --retries NUM           æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)
    --retry-delay SECONDS   é‡è¯•é—´éš” (é»˜è®¤: 2ç§’)
    --proxy URL             HTTPä»£ç†è®¾ç½®
    --headers HEADERS       è‡ªå®šä¹‰è¯·æ±‚å¤´ (æ ¼å¼: "Header1:Value1,Header2:Value2")

è¾“å‡ºé€‰é¡¹:
    --log-level LEVEL       æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARN/ERROR, é»˜è®¤: INFO)
    --output FORMAT         è¾“å‡ºæ ¼å¼ (console/json/junit, é»˜è®¤: console)
    --output-file FILE      ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„
    --save-responses        ä¿å­˜æ‰€æœ‰å“åº”åˆ°æ–‡ä»¶
    --test-data FILE        æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„

ç¯å¢ƒå˜é‡:
    API_BASE_URL            API åŸºç¡€ URL
    TOKEN                   è®¤è¯ token
    VERBOSE                 è¯¦ç»†è¾“å‡ºæ¨¡å¼ (true/false)
    TIMEOUT                 è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    MAX_RETRIES             å¤±è´¥è¯·æ±‚æœ€å¤§é‡è¯•æ¬¡æ•°
    RETRY_DELAY             é‡è¯•é—´éš”(ç§’)
    CONCURRENCY             å‹åŠ›æµ‹è¯•å¹¶å‘æ•°
    OUTPUT_FORMAT           è¾“å‡ºæ ¼å¼ (console/json/junit)
    LOG_LEVEL              æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARN/ERROR)
    TEST_SUITE             æµ‹è¯•å¥—ä»¶
    SKIP_HEALTH_CHECK      è·³è¿‡å¥åº·æ£€æŸ¥ (true/false)
    SAVE_RESPONSES         ä¿å­˜å“åº”åˆ°æ–‡ä»¶ (true/false)
    OUTPUT_FILE            æµ‹è¯•ç»“æœè¾“å‡ºæ–‡ä»¶
    PROXY                  HTTPä»£ç†è®¾ç½®
    CUSTOM_HEADERS         è‡ªå®šä¹‰è¯·æ±‚å¤´
    TEST_DATA_FILE         æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„
    FAIL_FAST              é‡åˆ°å¤±è´¥ç«‹å³åœæ­¢ (true/false)
    STRESS_TEST            å¯ç”¨å‹åŠ›æµ‹è¯• (true/false)

æµ‹è¯•çš„æ¥å£:
    GET /api/v1/workloads/:namespace/:name/scheduling
    GET /api/v1/workloads/:namespace/:name/precise-scheduling
    GET /api/v1/scheduling/overview
    GET /api/v1/scheduling/namespace/:namespace/workloads

ç¤ºä¾‹:
    # åŸºç¡€ä½¿ç”¨
    $0 --url http://localhost:8000 --verbose
    
    # å¸¦è®¤è¯å’Œè¾“å‡ºæ–‡ä»¶
    $0 --token your-jwt-token --output json --output-file results.json
    
    # ä»…è¿è¡Œå¥åº·æ£€æŸ¥
    $0 --suite health --log-level WARN
    
    # å‹åŠ›æµ‹è¯•
    $0 --stress --concurrency 10 --timeout 60
    
    # ä½¿ç”¨ä»£ç†å’Œè‡ªå®šä¹‰å¤´
    $0 --proxy http://proxy:8080 --headers "X-Custom:value,X-Test:123"
    
    # å¿«é€Ÿå¤±è´¥æ¨¡å¼
    $0 --fail-fast --retries 1
    
    # ä½¿ç”¨ç¯å¢ƒå˜é‡
    API_BASE_URL=http://localhost:8000 TOKEN=your-token VERBOSE=true $0

æµ‹è¯•æ•°æ®æ–‡ä»¶æ ¼å¼ (å¯é€‰):
    # test_data.sh
    # å¯ä»¥è¦†ç›–é»˜è®¤çš„æµ‹è¯•æ•°æ®
    namespaces=("custom-ns1" "custom-ns2")
    workload_names=("custom-app1" "custom-app2")
    workload_kinds=("Deployment" "StatefulSet")

EOF
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        # åŸºç¡€é€‰é¡¹
        --url)
            API_BASE_URL="$2"
            shift 2
            ;;
        --token)
            TOKEN="$2"
            shift 2
            ;;
        --verbose)
            VERBOSE="true"
            shift
            ;;
        --help)
            show_help
            exit 0
            ;;
        
        # æµ‹è¯•æ§åˆ¶é€‰é¡¹
        --suite)
            TEST_SUITE="$2"
            shift 2
            ;;
        --skip-health)
            SKIP_HEALTH_CHECK="true"
            shift
            ;;
        --stress)
            STRESS_TEST="true"
            shift
            ;;
        --fail-fast)
            FAIL_FAST="true"
            shift
            ;;
        --concurrency)
            CONCURRENCY="$2"
            shift 2
            ;;
        
        # ç½‘ç»œé€‰é¡¹
        --timeout)
            TIMEOUT="$2"
            shift 2
            ;;
        --retries)
            MAX_RETRIES="$2"
            shift 2
            ;;
        --retry-delay)
            RETRY_DELAY="$2"
            shift 2
            ;;
        --proxy)
            PROXY="$2"
            shift 2
            ;;
        --headers)
            CUSTOM_HEADERS="$2"
            shift 2
            ;;
        
        # è¾“å‡ºé€‰é¡¹
        --log-level)
            LOG_LEVEL="$2"
            shift 2
            ;;
        --output)
            OUTPUT_FORMAT="$2"
            shift 2
            ;;
        --output-file)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        --save-responses)
            SAVE_RESPONSES="true"
            shift
            ;;
        --test-data)
            TEST_DATA_FILE="$2"
            shift 2
            ;;
        
        *)
            echo "æœªçŸ¥é€‰é¡¹: $1"
            echo "ä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹"
            exit 1
            ;;
    esac
done

# éªŒè¯å‚æ•°
validate_parameters() {
    # éªŒè¯æµ‹è¯•å¥—ä»¶
    case "$TEST_SUITE" in
        "all"|"health"|"workload"|"overview"|"namespace"|"stress")
            ;;
        *)
            log_error "âŒ æ— æ•ˆçš„æµ‹è¯•å¥—ä»¶: $TEST_SUITE"
            log_error "   æ”¯æŒçš„å¥—ä»¶: all, health, workload, overview, namespace, stress"
            exit 1
            ;;
    esac
    
    # éªŒè¯è¾“å‡ºæ ¼å¼
    case "$OUTPUT_FORMAT" in
        "console"|"json"|"junit")
            ;;
        *)
            log_error "âŒ æ— æ•ˆçš„è¾“å‡ºæ ¼å¼: $OUTPUT_FORMAT"
            log_error "   æ”¯æŒçš„æ ¼å¼: console, json, junit"
            exit 1
            ;;
    esac
    
    # éªŒè¯æ—¥å¿—çº§åˆ«
    case "$LOG_LEVEL" in
        "DEBUG"|"INFO"|"WARN"|"ERROR")
            ;;
        *)
            log_error "âŒ æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: $LOG_LEVEL"
            log_error "   æ”¯æŒçš„çº§åˆ«: DEBUG, INFO, WARN, ERROR"
            exit 1
            ;;
    esac
    
    # éªŒè¯æ•°å€¼å‚æ•°
    if ! [[ "$TIMEOUT" =~ ^[0-9]+$ ]] || [[ "$TIMEOUT" -le 0 ]]; then
        log_error "âŒ è¶…æ—¶æ—¶é—´å¿…é¡»æ˜¯æ­£æ•´æ•°: $TIMEOUT"
        exit 1
    fi
    
    if ! [[ "$MAX_RETRIES" =~ ^[0-9]+$ ]] || [[ "$MAX_RETRIES" -lt 0 ]]; then
        log_error "âŒ é‡è¯•æ¬¡æ•°å¿…é¡»æ˜¯éè´Ÿæ•´æ•°: $MAX_RETRIES"
        exit 1
    fi
    
    if ! [[ "$RETRY_DELAY" =~ ^[0-9]+$ ]] || [[ "$RETRY_DELAY" -lt 0 ]]; then
        log_error "âŒ é‡è¯•é—´éš”å¿…é¡»æ˜¯éè´Ÿæ•´æ•°: $RETRY_DELAY"
        exit 1
    fi
    
    if ! [[ "$CONCURRENCY" =~ ^[0-9]+$ ]] || [[ "$CONCURRENCY" -le 0 ]]; then
        log_error "âŒ å¹¶å‘æ•°å¿…é¡»æ˜¯æ­£æ•´æ•°: $CONCURRENCY"
        exit 1
    fi
    
    # éªŒè¯æµ‹è¯•æ•°æ®æ–‡ä»¶
    if [[ -n "$TEST_DATA_FILE" ]] && [[ ! -f "$TEST_DATA_FILE" ]]; then
        log_error "âŒ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: $TEST_DATA_FILE"
        exit 1
    fi
}

# æ‰§è¡Œå‚æ•°éªŒè¯
validate_parameters

# ä¸»æµ‹è¯•å‡½æ•°
run_all_tests() {
    local start_time=$(date +%s)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    load_test_data
    
    log_info "ğŸ¯ å¼€å§‹è¿è¡Œ Karmada Dashboard è°ƒåº¦æ¥å£æµ‹è¯•..."
    log_info "ğŸŒ API åŸºç¡€ URL: $API_BASE_URL"
    log_info "ğŸ“‹ æµ‹è¯•å¥—ä»¶: $TEST_SUITE"
    log_info "ğŸ“Š è¾“å‡ºæ ¼å¼: $OUTPUT_FORMAT"
    log_info "ğŸ“ æ—¥å¿—çº§åˆ«: $LOG_LEVEL"
    
    if [[ -n "$TOKEN" ]]; then
        log_info "ğŸ” ä½¿ç”¨è®¤è¯ Token: ${TOKEN:0:20}..."
    else
        log_warning "âš ï¸  æœªæä¾›è®¤è¯ Tokenï¼ŒæŸäº›æ¥å£å¯èƒ½è¿”å› 401/403"
    fi
    
    if [[ "$VERBOSE" == "true" ]] || [[ "$LOG_LEVEL" == "DEBUG" ]]; then
        log_info "ğŸ” è¯¦ç»†æ¨¡å¼å·²å¯ç”¨"
    fi
    
    if [[ "$STRESS_TEST" == "true" ]]; then
        log_info "âš¡ å‹åŠ›æµ‹è¯•å·²å¯ç”¨ (å¹¶å‘æ•°: $CONCURRENCY)"
    fi
    
    if [[ "$FAIL_FAST" == "true" ]]; then
        log_info "ğŸ’¥ å¿«é€Ÿå¤±è´¥æ¨¡å¼å·²å¯ç”¨"
    fi
    
    if [[ -n "$PROXY" ]]; then
        log_info "ğŸŒ ä½¿ç”¨ä»£ç†: $PROXY"
    fi
    
    if [[ "$SAVE_RESPONSES" == "true" ]]; then
        log_info "ğŸ’¾ å“åº”å°†ä¿å­˜åˆ°: $RESPONSE_DIR"
        mkdir -p "$RESPONSE_DIR"
    fi
    
    echo "===================================================="
    
    # æ‰§è¡Œæµ‹è¯•ï¼Œä½¿ç”¨ trap æ•è·ä¸­æ–­ä¿¡å·
    trap 'cleanup_and_exit 130' INT TERM
    
    # æ ¹æ®æµ‹è¯•å¥—ä»¶é€‰æ‹©æ€§æ‰§è¡Œæµ‹è¯•
    case "$TEST_SUITE" in
        "all")
            test_health_check || true
            test_workload_scheduling_apis || true
            test_scheduling_overview_apis || true
            test_namespace_workloads_scheduling_apis || true
            test_scheduling_stress_test || true
            ;;
        "health")
            test_health_check || true
            ;;
        "workload")
            test_workload_scheduling_apis || true
            ;;
        "overview")
            test_scheduling_overview_apis || true
            ;;
        "namespace")
            test_namespace_workloads_scheduling_apis || true
            ;;
        "stress")
            test_scheduling_stress_test || true
            ;;
    esac
    
    echo "===================================================="
    
    # è®¡ç®—è€—æ—¶
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ±‡æ€»
    should_log "INFO" && log_info "ğŸ“Š è°ƒåº¦æ¥å£æµ‹è¯•ç»“æœæ±‡æ€»:"
    echo "  ğŸ“ˆ æ€»æµ‹è¯•æ•°: $TOTAL_TESTS"
    echo "  âœ… é€šè¿‡æ•°: $PASSED_TESTS"
    echo "  âŒ å¤±è´¥æ•°: $FAILED_TESTS"
    echo "  â­ï¸  è·³è¿‡æ•°: $SKIPPED_TESTS"
    echo "  â±ï¸  æµ‹è¯•è€—æ—¶: ${duration} ç§’"
    
    if [[ $TOTAL_TESTS -gt 0 ]]; then
        local success_rate=$((PASSED_TESTS * 100 / TOTAL_TESTS))
        echo "  ğŸ“Š æˆåŠŸç‡: ${success_rate}%"
        
        if [[ $success_rate -eq 100 ]]; then
            log_success "ğŸ‰ æ‰€æœ‰è°ƒåº¦æ¥å£æµ‹è¯•é€šè¿‡ï¼"
        elif [[ $success_rate -ge 80 ]]; then
            log_warning "âš ï¸  å¤§éƒ¨åˆ†è°ƒåº¦æ¥å£æµ‹è¯•é€šè¿‡ï¼Œå°‘æ•°å¤±è´¥"
        else
            log_error "âŒ å¤šä¸ªè°ƒåº¦æ¥å£æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æœåŠ¡çŠ¶æ€"
        fi
    fi
    
    echo "===================================================="
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    output_test_results
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f /tmp/scheduling_api_response*.json /tmp/scheduling_curl_error.log
    
    # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
    if [[ $FAILED_TESTS -eq 0 ]]; then
        exit 0
    else
        exit 1
    fi
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    local missing_deps=()
    
    if ! command -v curl &> /dev/null; then
        missing_deps+=("curl")
    fi
    
    if ! command -v bc &> /dev/null; then
        log_warning "âš ï¸  bc æœªå®‰è£…ï¼Œæ—¶é—´è®¡ç®—å¯èƒ½ä¸å‡†ç¡®"
        log_info "ğŸ’¡ å®‰è£… bc è·å¾—ç²¾ç¡®çš„å“åº”æ—¶é—´: sudo yum install bc æˆ– sudo apt install bc"
    fi
    
    if ! command -v jq &> /dev/null; then
        log_warning "âš ï¸  jq æœªå®‰è£…ï¼ŒJSON å“åº”å°†ä»¥åŸå§‹æ ¼å¼æ˜¾ç¤º"
        log_info "ğŸ’¡ å®‰è£… jq å¯è·å¾—æ›´å¥½çš„ JSON æ ¼å¼åŒ–æ˜¾ç¤º: sudo yum install jq æˆ– sudo apt install jq"
        
        # å¦‚æœé€‰æ‹©äº†JSONè¾“å‡ºæ ¼å¼ä½†æ²¡æœ‰jqï¼Œç»™å‡ºè­¦å‘Š
        if [[ "$OUTPUT_FORMAT" == "json" ]]; then
            log_warning "âš ï¸  JSON è¾“å‡ºæ ¼å¼éœ€è¦ jq å·¥å…·ï¼Œå»ºè®®å®‰è£…åé‡æ–°è¿è¡Œ"
        fi
    fi
    
    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        log_error "âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–: ${missing_deps[*]}"
        echo "è¯·å®‰è£…è¿™äº›å·¥å…·åå†è¿è¡Œæµ‹è¯•"
        exit 1
    fi
}

# ä¸»ç¨‹åºå…¥å£
main() {
    # æ£€æŸ¥ä¾èµ–
    check_dependencies
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    echo "=================================================="
    echo "ğŸ“‹ Karmada Dashboard è°ƒåº¦æ¥å£æµ‹è¯•è„šæœ¬"
    echo "ğŸ“… å¯åŠ¨æ—¶é—´: $(date)"
    echo "ğŸ–¥ï¸  è¿è¡Œç¯å¢ƒ: $(uname -s) $(uname -r)"
    echo "ğŸ¯ æµ‹è¯•ç›®æ ‡: è°ƒåº¦ç›¸å…³ API æ¥å£"
    echo "=================================================="
    
    # è¿è¡Œæµ‹è¯•
    run_all_tests
}

# å¦‚æœè„šæœ¬è¢«ç›´æ¥æ‰§è¡Œï¼Œåˆ™è¿è¡Œä¸»å‡½æ•°
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi 